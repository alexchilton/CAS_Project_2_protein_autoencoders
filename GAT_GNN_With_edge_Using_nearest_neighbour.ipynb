{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:34.327456Z",
     "start_time": "2024-11-12T20:00:34.302665Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:34.403939Z",
     "start_time": "2024-11-12T20:00:34.341917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports and setup\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set environment variable for MPS fallback\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Device setup\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device with fallbacks\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        logger.info(\"MPS (M1/M2) device found but using CPU for some operations due to compatibility\")\n",
    "        return torch.device('cpu')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import logging\n",
    "\n",
    "class MolecularGVAE(nn.Module):\n",
    "    def __init__(self, node_features=3, hidden_dim=64, latent_dim=32):\n",
    "        super(MolecularGVAE, self).__init__()\n",
    "        self.node_features = node_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder layers\n",
    "        self.enc_conv1 = GATv2Conv(node_features, hidden_dim)\n",
    "        self.enc_conv2 = GATv2Conv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Use GroupNorm instead of BatchNorm\n",
    "        self.enc_norm1 = nn.GroupNorm(8, hidden_dim)\n",
    "        self.enc_norm2 = nn.GroupNorm(8, hidden_dim)\n",
    "\n",
    "        # Latent space\n",
    "        self.node_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.node_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # Decoder for node features\n",
    "        self.dec_node_features = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(8, hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(8, hidden_dim),\n",
    "            nn.Linear(hidden_dim, node_features)\n",
    "        )\n",
    "\n",
    "        # Edge prediction\n",
    "        self.edge_pred = nn.Sequential(\n",
    "            nn.Linear(2 * latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(8, hidden_dim),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        if x.device.type == 'mps':\n",
    "            x = x.cpu()\n",
    "            edge_index = edge_index.cpu()\n",
    "\n",
    "        h = self.enc_conv1(x, edge_index)\n",
    "        h = h.view(-1, self.hidden_dim)\n",
    "        h = F.relu(self.enc_norm1(h))\n",
    "        h = self.enc_conv2(h, edge_index)\n",
    "        h = h.view(-1, self.hidden_dim)\n",
    "        h = F.relu(self.enc_norm2(h))\n",
    "\n",
    "        h = h.to(data.x.device)\n",
    "\n",
    "        return self.node_mu(h), self.node_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        return mu\n",
    "\n",
    "    def decode(self, z, num_nodes):\n",
    "        # Reconstruct node features\n",
    "        node_features = self.dec_node_features(z)\n",
    "\n",
    "        # Create full adjacency matrix of predictions\n",
    "        edge_logits = torch.zeros((num_nodes, num_nodes), device=z.device)\n",
    "\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i + 1, num_nodes):\n",
    "                # CPU fallback for MPS\n",
    "                if z.device.type == 'mps':\n",
    "                    zi = z[i].cpu()\n",
    "                    zj = z[j].cpu()\n",
    "                else:\n",
    "                    zi = z[i]\n",
    "                    zj = z[j]\n",
    "\n",
    "                edge_input = torch.cat([zi, zj], dim=0)\n",
    "                edge_input = edge_input.unsqueeze(0).to(z.device)\n",
    "                pred = self.edge_pred(edge_input)\n",
    "\n",
    "                # Make the adjacency matrix symmetric\n",
    "                edge_logits[i, j] = pred\n",
    "                edge_logits[j, i] = pred  # Symmetric edge prediction\n",
    "\n",
    "        return node_features, edge_logits\n",
    "\n",
    "    def forward(self, data):\n",
    "        mu, logvar = self.encode(data)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        node_features, edge_logits = self.decode(z, data.x.size(0))\n",
    "        return node_features, edge_logits, mu, logvar\n",
    "\n",
    "    def loss_function(self, node_features, edge_logits, data, node_mu, node_logvar):\n",
    "        # Node feature reconstruction loss\n",
    "        recon_loss = F.mse_loss(node_features, data.x)\n",
    "\n",
    "        # Edge prediction loss\n",
    "        if edge_logits.numel() > 0:\n",
    "            # Convert edge_index to dense adjacency matrix\n",
    "            adj = to_dense_adj(data.edge_index, max_num_nodes=data.x.size(0))[0]\n",
    "\n",
    "            # Binary cross entropy loss on the entire adjacency matrix\n",
    "            edge_loss = F.binary_cross_entropy_with_logits(edge_logits, adj)\n",
    "        else:\n",
    "            edge_loss = torch.tensor(0.0).to(node_features.device)\n",
    "\n",
    "        # KL divergence loss\n",
    "        kl_loss = -0.5 * torch.mean(1 + node_logvar - node_mu.pow(2) - node_logvar.exp())\n",
    "\n",
    "        # Weight the losses\n",
    "        total_loss = recon_loss + edge_loss + 0.1 * kl_loss\n",
    "\n",
    "        return total_loss, {\n",
    "            'recon': recon_loss.item(),\n",
    "            'edge': edge_loss.item(),\n",
    "            'kl': kl_loss.item()\n",
    "        }\n",
    "    \n",
    "    \n",
    "class TrainingManager:\n",
    "    def __init__(self, model_name, checkpoint_dir='checkpoints'):\n",
    "        self.model_name = model_name\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.train_metrics = defaultdict(list)\n",
    "        self.val_metrics = defaultdict(list)\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    def save_checkpoint(self, epoch, model, optimizer, train_loss, val_loss, metrics):\n",
    "        checkpoint_path = self.checkpoint_dir / f\"{self.model_name}_{self.run_id}_epoch{epoch}.pt\"\n",
    "        metrics_path = self.checkpoint_dir / f\"{self.model_name}_{self.run_id}_metrics.json\"\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_metrics': dict(self.train_metrics),\n",
    "            'val_metrics': dict(self.val_metrics)\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "        metrics_dict = {\n",
    "            'train': dict(self.train_metrics),\n",
    "            'val': dict(self.val_metrics)\n",
    "        }\n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(metrics_dict, f, indent=4)\n",
    "\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            best_path = self.checkpoint_dir / f\"{self.model_name}_{self.run_id}_best.pt\"\n",
    "            torch.save(checkpoint, best_path)\n",
    "            logger.info(f\"\\nNew best model saved with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "    def update_metrics(self, epoch_metrics, phase='train'):\n",
    "        metrics_dict = self.train_metrics if phase == 'train' else self.val_metrics\n",
    "        for key, value in epoch_metrics.items():\n",
    "            metrics_dict[key].append(value)\n",
    "\n",
    "    def plot_training_progress(self):\n",
    "        metrics = list(self.train_metrics.keys())\n",
    "        n_metrics = len(metrics)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_metrics, 1, figsize=(12, 4*n_metrics))\n",
    "        if n_metrics == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, metric in zip(axes, metrics):\n",
    "            train_values = self.train_metrics[metric]\n",
    "            ax.plot(train_values, label=f'Train {metric}', color='blue', alpha=0.7)\n",
    "            \n",
    "            if metric in self.val_metrics:\n",
    "                val_values = self.val_metrics[metric]\n",
    "                ax.plot(val_values, label=f'Val {metric}', color='red', alpha=0.7)\n",
    "            \n",
    "            ax.set_title(f'{metric} over Training')\n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel(metric)\n",
    "            ax.grid(True)\n",
    "            ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "6867224ed7979dc0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/38fnv8v91rqdkwbf17xlnxyh0000gn/T/ipykernel_94049/65936390.py:29: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:34.462348Z",
     "start_time": "2024-11-12T20:00:34.455513Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f7835c064beec29e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:34.523050Z",
     "start_time": "2024-11-12T20:00:34.488172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, n_epochs=100, device='cpu',\n",
    "                patience=10, checkpoint_frequency=5, max_grad_norm=1.0):\n",
    "    \"\"\"Training loop with validation and early stopping\"\"\"\n",
    "    manager = TrainingManager('molecular_gvae')\n",
    "\n",
    "    # Early stopping setup\n",
    "    patience_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_batch_metrics = defaultdict(float)\n",
    "\n",
    "        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{n_epochs} [Train]') as train_pbar:\n",
    "            for batch in train_pbar:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass using the model's forward method\n",
    "                node_features, edge_logits, mu, logvar = model(batch)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss, metrics = model.loss_function(\n",
    "                    node_features, edge_logits,\n",
    "                    batch, mu, logvar\n",
    "                )\n",
    "\n",
    "                # Backward pass with gradient clipping\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update metrics\n",
    "                train_loss += loss.item()\n",
    "                for k, v in metrics.items():\n",
    "                    train_batch_metrics[k] += v\n",
    "\n",
    "                # Update progress bar\n",
    "                train_pbar.set_postfix({\n",
    "                    'loss': train_loss / (train_pbar.n + 1),\n",
    "                    **{k: v / (train_pbar.n + 1) for k, v in train_batch_metrics.items()}\n",
    "                })\n",
    "\n",
    "        # Calculate average training metrics\n",
    "        avg_train_metrics = {k: v / len(train_loader) for k, v in train_batch_metrics.items()}\n",
    "        avg_train_metrics['total_loss'] = train_loss / len(train_loader)\n",
    "        manager.update_metrics(avg_train_metrics, 'train')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_batch_metrics = defaultdict(float)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(val_loader, desc=f'Epoch {epoch+1}/{n_epochs} [Val]') as val_pbar:\n",
    "                for batch in val_pbar:\n",
    "                    batch = batch.to(device)\n",
    "\n",
    "                    # Forward pass using the model's forward method\n",
    "                    node_features, edge_logits, mu, logvar = model(batch)\n",
    "\n",
    "                    # Calculate loss\n",
    "                    loss, metrics = model.loss_function(\n",
    "                        node_features, edge_logits,\n",
    "                        batch, mu, logvar\n",
    "                    )\n",
    "\n",
    "                    # Update metrics\n",
    "                    val_loss += loss.item()\n",
    "                    for k, v in metrics.items():\n",
    "                        val_batch_metrics[k] += v\n",
    "\n",
    "                    # Update progress bar\n",
    "                    val_pbar.set_postfix({\n",
    "                        'loss': val_loss / (val_pbar.n + 1),\n",
    "                        **{k: v / (val_pbar.n + 1) for k, v in val_batch_metrics.items()}\n",
    "                    })\n",
    "\n",
    "        # Calculate average validation metrics\n",
    "        avg_val_metrics = {k: v / len(val_loader) for k, v in val_batch_metrics.items()}\n",
    "        avg_val_metrics['total_loss'] = val_loss / len(val_loader)\n",
    "        manager.update_metrics(avg_val_metrics, 'val')\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_metrics['total_loss'] < best_val_loss:\n",
    "            best_val_loss = avg_val_metrics['total_loss']\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % checkpoint_frequency == 0:\n",
    "            manager.save_checkpoint(\n",
    "                epoch, model, optimizer,\n",
    "                avg_train_metrics['total_loss'],\n",
    "                avg_val_metrics['total_loss'],\n",
    "                {'train': avg_train_metrics, 'val': avg_val_metrics}\n",
    "            )\n",
    "            manager.plot_training_progress()\n",
    "\n",
    "        # Print epoch summary\n",
    "        logger.info(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "        logger.info(f\"Train Loss: {avg_train_metrics['total_loss']:.4f}\")\n",
    "        logger.info(f\"Val Loss: {avg_val_metrics['total_loss']:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            logger.info(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "    return manager\n",
    "\n",
    "def plot_latent_space(model, loader, device):\n",
    "    \"\"\"Visualize the latent space using PCA\"\"\"\n",
    "    model.eval()\n",
    "    latent_vectors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            mu, _ = model.encode(batch)\n",
    "            latent_vectors.append(mu.cpu().numpy())\n",
    "\n",
    "    latent_vectors = np.concatenate(latent_vectors, axis=0)\n",
    "\n",
    "    # PCA visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    latent_2d = pca.fit_transform(latent_vectors)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(latent_2d[:, 0], latent_2d[:, 1], alpha=0.5)\n",
    "    plt.title('Latent Space Visualization (PCA)')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.show()"
   ],
   "id": "1e283ffb00a6ed45",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:34.579252Z",
     "start_time": "2024-11-12T20:00:34.571559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the file for a demo protein structure\n",
    "pdb_file = '/Users/alexchilton/Downloads/archive/train/AF-D0ZA02-F1-model_v4.pdb'\n",
    "\n",
    "# Define the directory containing the PDB files\n",
    "pdb_directory = '/Users/alexchilton/Downloads/archive/just100'\n",
    "\n",
    "# Define the file containing amino acid information\n",
    "aa_info_file = 'aa_mass_letter.csv'"
   ],
   "id": "fbb45585736df69a",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:35.261103Z",
     "start_time": "2024-11-12T20:00:34.599781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ProteinAnalyzer import ProteinAnalyzer\n",
    "def load_pdb_files(directory):\n",
    "    ''' Load all PDB files from the specified directory '''\n",
    "    pdb_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdb')]\n",
    "    return pdb_files\n",
    "\n",
    "def create_autoencoder_input_dfs(pdb_files, aa_info_file):\n",
    "    ''' Create autoencoder input DataFrames for all PDB files '''\n",
    "    autoencoder_input_dfs = []\n",
    "    for pdb_file in pdb_files:\n",
    "        analyzer = ProteinAnalyzer(pdb_file, aa_info_file)\n",
    "        autoencoder_input_df = analyzer.prepare_autoencoder_input()\n",
    "        autoencoder_input_dfs.append(autoencoder_input_df)\n",
    "    return autoencoder_input_dfs\n",
    "\n",
    "\n",
    "# Load PDB files\n",
    "pdb_files = load_pdb_files(pdb_directory)\n",
    "\n",
    "# Create autoencoder input DataFrames\n",
    "autoencoder_input_dfs = create_autoencoder_input_dfs(pdb_files, aa_info_file)"
   ],
   "id": "8d14a27cb54bb16e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:35.363087Z",
     "start_time": "2024-11-12T20:00:35.282662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Utils import Utils\n",
    "# Assuming autoencoder_input_dfs is already defined convert the onject types to float\n",
    "autoencoder_input_dfs = Utils.convert_columns_to_float(autoencoder_input_dfs)\n",
    "\n",
    "# Verify the conversion\n",
    "print(autoencoder_input_dfs[0].dtypes)\n",
    "print(autoencoder_input_dfs[0].head())"
   ],
   "id": "248f17466adaa375",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X                    float64\n",
      "Y                    float64\n",
      "Z                    float64\n",
      "AA                    object\n",
      "Avg_Mass             float64\n",
      "Avg_Neighbor_Dist    float64\n",
      "Max_Neighbor_Dist    float64\n",
      "Neighbor_Count       float64\n",
      "dtype: object\n",
      "       X      Y      Z AA   Avg_Mass  Avg_Neighbor_Dist  Max_Neighbor_Dist  \\\n",
      "0 -3.361  0.103  5.039  I  131.17464           3.862061           3.862061   \n",
      "1 -0.566 -2.557  5.206  I  131.17464           3.860735           3.862061   \n",
      "2 -1.398 -3.989  1.720  E  147.13074           3.856269           3.859410   \n",
      "3 -1.416 -0.429  0.246  K  146.18934           3.852071           3.853129   \n",
      "4  1.985  0.279  1.908  L  131.17464           3.853064           3.855114   \n",
      "\n",
      "   Neighbor_Count  \n",
      "0             1.0  \n",
      "1             2.0  \n",
      "2             2.0  \n",
      "3             2.0  \n",
      "4             2.0  \n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:35.500555Z",
     "start_time": "2024-11-12T20:00:35.383685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from Utils import Utils\n",
    "# Assuming autoencoder_input_dfs is already defined\n",
    "onehot_encoder = Utils.create_onehot_encoder(autoencoder_input_dfs)\n",
    "\n",
    "encoded_autoencoder_input_dfs = [Utils.encode_values(df, onehot_encoder) for df in autoencoder_input_dfs]\n",
    "#decoded_autoencoder_input_dfs = [decode_values(df) for df in new_autoencoder_input_dfs]\n",
    "\n",
    "# Print the first few rows of the first encoded and decoded DataFrame\n",
    "print(encoded_autoencoder_input_dfs[0].head())\n",
    "#print(decoded_autoencoder_input_dfs[0].head())"
   ],
   "id": "3e177eafed5017d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X      Y      Z   Avg_Mass  Avg_Neighbor_Dist  Max_Neighbor_Dist  \\\n",
      "0 -3.361  0.103  5.039  131.17464           3.862061           3.862061   \n",
      "1 -0.566 -2.557  5.206  131.17464           3.860735           3.862061   \n",
      "2 -1.398 -3.989  1.720  147.13074           3.856269           3.859410   \n",
      "3 -1.416 -0.429  0.246  146.18934           3.852071           3.853129   \n",
      "4  1.985  0.279  1.908  131.17464           3.853064           3.855114   \n",
      "\n",
      "   Neighbor_Count  AA_A  AA_C  AA_D  ...  AA_M  AA_N  AA_P  AA_Q  AA_R  AA_S  \\\n",
      "0             1.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1             2.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2             2.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3             2.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "4             2.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "   AA_T  AA_V  AA_W  AA_Y  \n",
      "0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:00:36.032771Z",
     "start_time": "2024-11-12T20:00:35.523797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell for data preparation\n",
    "def create_graphs_from_df_array(df_array, k=3):\n",
    "    \"\"\"Convert array of DataFrames to list of PyG Data objects\"\"\"\n",
    "    graphs = []\n",
    "\n",
    "    for df in tqdm(df_array, desc=\"Creating graphs\"):\n",
    "        # Extract coordinates and create distance matrix\n",
    "        coords = df[['X', 'Y', 'Z']].values\n",
    "        distances = torch.cdist(torch.tensor(coords), torch.tensor(coords))\n",
    "\n",
    "        # Get k nearest neighbors\n",
    "        _, neighbor_indices = distances.topk(k + 1, largest=False)\n",
    "        neighbor_indices = neighbor_indices[:, 1:]  # Remove self-loops\n",
    "\n",
    "        # Create edge_index\n",
    "        rows = torch.arange(len(df)).unsqueeze(1).repeat(1, k)\n",
    "        edge_index = torch.stack([\n",
    "            rows.flatten(),\n",
    "            neighbor_indices.flatten()\n",
    "        ])\n",
    "\n",
    "        # Create node features\n",
    "        feature_cols = [col for col in df.columns if col.startswith('AA_')]\n",
    "        features = df[feature_cols].values\n",
    "        other_features = df[['Avg_Mass', 'Avg_Neighbor_Dist', 'Max_Neighbor_Dist']].values\n",
    "        node_features = np.concatenate([features, other_features], axis=1)\n",
    "\n",
    "        # Create and append graph\n",
    "        graph = Data(\n",
    "            x=torch.tensor(node_features, dtype=torch.float),\n",
    "            edge_index=edge_index,\n",
    "            pos=torch.tensor(coords, dtype=torch.float)\n",
    "        )\n",
    "        graphs.append(graph)\n",
    "\n",
    "    return graphs\n",
    "\n",
    "# Load and process data\n",
    "# Assuming df_array is your array of DataFrames\n",
    "print(f\"Processing {len(autoencoder_input_dfs)} structures...\")\n",
    "\n",
    "# Create graphs\n",
    "graphs = create_graphs_from_df_array(autoencoder_input_dfs)\n",
    "print(f\"Created {len(graphs)} graphs\")\n",
    "\n",
    "# Split into train/validation sets\n",
    "train_size = int(0.8 * len(graphs))\n",
    "train_graphs = graphs[:train_size]\n",
    "val_graphs = graphs[train_size:]\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Validation loader: {len(val_loader)} batches\")\n",
    "\n",
    "# Optional: Quick data inspection\n",
    "sample_graph = graphs[0]\n",
    "print(\"\\nSample graph statistics:\")\n",
    "print(f\"Number of nodes: {sample_graph.x.size(0)}\")\n",
    "print(f\"Number of edges: {sample_graph.edge_index.size(1)}\")\n",
    "print(f\"Node feature dimension: {sample_graph.x.size(1)}\")\n",
    "\n",
    "# Visualize node degree distribution of first few graphs\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(min(5, len(graphs))):\n",
    "    degrees = torch.bincount(graphs[i].edge_index[0])\n",
    "    plt.hist(degrees.numpy(), alpha=0.3, bins=20, label=f'Graph {i}')\n",
    "plt.title('Node Degree Distribution')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "42f06ff0d2d32404",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 structures...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Creating graphs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "257a07a8831244e58f61112d798fc9b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 100 graphs\n",
      "Train loader: 3 batches\n",
      "Validation loader: 1 batches\n",
      "\n",
      "Sample graph statistics:\n",
      "Number of nodes: 16\n",
      "Number of edges: 48\n",
      "Node feature dimension: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:03:52.308296Z",
     "start_time": "2024-11-12T20:00:36.054629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "def main():\n",
    "    # Set device\n",
    "    device = get_device()\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    # Create data loaders (assuming you have your graphs ready)\n",
    "    train_loader = DataLoader(train_graphs, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_graphs, batch_size=16, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model = MolecularGVAE(\n",
    "        node_features=3,  # Update based on your data\n",
    "        hidden_dim=64,\n",
    "        latent_dim=32\n",
    "    ).to(device)\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train model\n",
    "    training_manager = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        n_epochs=100,\n",
    "        device=device,\n",
    "        patience=10,\n",
    "        checkpoint_frequency=5,\n",
    "        max_grad_norm=1.0\n",
    "    )\n",
    "\n",
    "    # Visualize results\n",
    "    plot_latent_space(model, train_loader, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "d5381cf785fafce3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MPS (M1/M2) device found but using CPU for some operations due to compatibility\n",
      "INFO:__main__:Using device: cpu\n",
      "/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1/100 [Train]:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e756bd4cf9a49d7ba5d8a3861d30b24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1/100 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eecb56bcdabb444288e47359d5170914"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Epoch 1/100\n",
      "INFO:__main__:Train Loss: 5458.6343\n",
      "INFO:__main__:Val Loss: 5187.4495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2/100 [Train]:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b68f68f3c74c4693a66fb2b3fe3c8c79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 38\u001B[0m\n\u001B[1;32m     35\u001B[0m     plot_latent_space(model, train_loader, device)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 38\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[32], line 22\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     19\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m training_manager \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheckpoint_frequency\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_grad_norm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\n\u001B[1;32m     32\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Visualize results\u001B[39;00m\n\u001B[1;32m     35\u001B[0m plot_latent_space(model, train_loader, device)\n",
      "Cell \u001B[0;32mIn[26], line 30\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, train_loader, val_loader, optimizer, n_epochs, device, patience, checkpoint_frequency, max_grad_norm)\u001B[0m\n\u001B[1;32m     27\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Forward pass using the model's forward method\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m node_features, edge_logits, mu, logvar \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Calculate loss\u001B[39;00m\n\u001B[1;32m     33\u001B[0m loss, metrics \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mloss_function(\n\u001B[1;32m     34\u001B[0m     node_features, edge_logits,\n\u001B[1;32m     35\u001B[0m     batch, mu, logvar\n\u001B[1;32m     36\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[25], line 148\u001B[0m, in \u001B[0;36mMolecularGVAE.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    146\u001B[0m mu, logvar \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode(data)\n\u001B[1;32m    147\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreparameterize(mu, logvar)\n\u001B[0;32m--> 148\u001B[0m node_features, edge_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m node_features, edge_logits, mu, logvar\n",
      "Cell \u001B[0;32mIn[25], line 137\u001B[0m, in \u001B[0;36mMolecularGVAE.decode\u001B[0;34m(self, z, num_nodes)\u001B[0m\n\u001B[1;32m    135\u001B[0m edge_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([zi, zj], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    136\u001B[0m edge_input \u001B[38;5;241m=\u001B[39m edge_input\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mto(z\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 137\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_pred\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;66;03m# Make the adjacency matrix symmetric\u001B[39;00m\n\u001B[1;32m    140\u001B[0m edge_logits[i, j] \u001B[38;5;241m=\u001B[39m pred\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/normalization.py:288\u001B[0m, in \u001B[0;36mGroupNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mgroup_norm(\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_groups, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meps)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/torch/nn/modules/module.py:1678\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1676\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n\u001B[1;32m   1677\u001B[0m     _parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m-> 1678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_parameters\u001B[49m:\n\u001B[1;32m   1679\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _parameters[name]\n\u001B[1;32m   1680\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_buffers\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
